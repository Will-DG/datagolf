{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, define function to count unique words in a string\n",
    "\n",
    "def count_unique_words(my_string):\n",
    "    \n",
    "    # function that takes a string of words and counts the number \n",
    "    # of times each unique word appears\n",
    "    punctuation = \"',.\"\n",
    "    no_punc = \"\"\n",
    "    # get rid of punctuation\n",
    "    for i in my_string:\n",
    "        if i not in punctuation:\n",
    "            no_punc = no_punc + i\n",
    "        else:\n",
    "            no_punc = no_punc\n",
    "        \n",
    "    # make a list with each element as a word from string\n",
    "    # get everything lower case\n",
    "    words = str.lower(no_punc).split()\n",
    "    \n",
    "    # get rid Tiger's name and all words under 4 letters\n",
    "    unwanted_words = ['tiger', 'woods:']\n",
    "    words = [word for word in words if word not in unwanted_words]\n",
    "    words = [word for word in words if len(word) > 3]\n",
    "    # get list of unique words\n",
    "    unique_words = []\n",
    "    for i in words:\n",
    "        if i not in unique_words:\n",
    "            unique_words.append(i)\n",
    "\n",
    "    # count number of times each unique word appears\n",
    "    word_counter = []\n",
    "    for i in unique_words:\n",
    "        count = 0\n",
    "        for j in words:\n",
    "            if i == j:\n",
    "                count += 1\n",
    "        word_counter.append(count)\n",
    "\n",
    "    # make DataFrame\n",
    "    data =  np.column_stack((unique_words, word_counter))\n",
    "    data2 = pd.DataFrame(data=data, columns = ['word', 'count'])\n",
    "    return(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching: February 2, 2017 - OMEGA DUBAI DESERT CLASSIC...\n",
      "fetching: February 1, 2017 - OMEGA DUBAI DESERT CLASSIC...\n",
      "fetching: October 2, 2016 - THE RYDER CUP...\n",
      "fetching: August 23, 2015 - WYNDHAM CHAMPIONSHIP...\n",
      "fetching: August 22, 2015 - WYNDHAM CHAMPIONSHIP...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "r_main = requests.get('http://www.asapsports.com/show_player.php?id=10085')\n",
    "main_soup = BeautifulSoup(r_main.content, 'html.parser')\n",
    "\n",
    "final_data = pd.DataFrame()\n",
    "\n",
    "for interview in main_soup.findAll('table')[-2].findAll('tr')[:5]:\n",
    "    date = interview.find('nobr').get_text().replace('[ ', '').replace(' ]', '')\n",
    "    event = interview.find('a').get_text()\n",
    "    link = interview.find('a')['href']\n",
    "    print('fetching: ' + date + ' - ' + event + '...')\n",
    "    \n",
    "    # use the link to scrape his interview\n",
    "    r_sub = requests.get(link)\n",
    "    sub_soup = BeautifulSoup(r_sub.content, 'html.parser')\n",
    "    # loop through all elements that contain text: 'TIGER WOODS:'\n",
    "    all_words = ''\n",
    "    for answer in sub_soup.findAll(text = re.compile('TIGER WOODS:')):\n",
    "        # get text and replace his name, comma, period\n",
    "        text = answer.lstrip().replace('TIGER WOODS: ', '').replace(',', '').replace('.', ' ')\n",
    "        all_words += text\n",
    "    \n",
    "    # run function to clean text and count unique words\n",
    "    data = count_unique_words(all_words)\n",
    "    # add columns to data frame\n",
    "    data['date'] = date\n",
    "    data['event'] = event\n",
    "    \n",
    "    final_data = final_data.append(data)\n",
    "    \n",
    "print('Done!')\n",
    "\n",
    "#write to csv\n",
    "final_data.to_csv('~\\Dropbox\\tiger_interviews', index= False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching: February 2, 2017 - OMEGA DUBAI DESERT CLASSIC...\n",
      "fetching: February 1, 2017 - OMEGA DUBAI DESERT CLASSIC...\n",
      "fetching: October 2, 2016 - THE RYDER CUP...\n",
      "fetching: August 23, 2015 - WYNDHAM CHAMPIONSHIP...\n",
      "fetching: August 22, 2015 - WYNDHAM CHAMPIONSHIP...\n",
      "Done!!\n"
     ]
    }
   ],
   "source": [
    "r_main = requests.get('http://www.asapsports.com/show_player.php?id=10085')\n",
    "main_soup = BeautifulSoup(r_main.content, 'html.parser')\n",
    "\n",
    "all_data = []\n",
    "\n",
    "# loop through all the interviews (only does 5 for testing)\n",
    "for interview in main_soup.findAll('table')[-2].findAll('tr')[:5]: # this is only going to do the first 5!!\n",
    "    # get the date, event, and link\n",
    "    date = interview.find('nobr').get_text().replace('[ ', '').replace(' ]', '')\n",
    "    event = interview.find('a').get_text()\n",
    "    link = interview.find('a')['href']\n",
    "    print('fetching: ' + date + ' - ' + event + '...')\n",
    "    \n",
    "    # use the link to scrape his interview\n",
    "    r_sub = requests.get(link)\n",
    "    sub_soup = BeautifulSoup(r_sub.content, 'html.parser')\n",
    "    # loop through all elements that contain text: 'TIGER WOODS:'\n",
    "    for answer in sub_soup.findAll(text = re.compile('TIGER WOODS:')):\n",
    "        new = {}\n",
    "        # get text and replace his name, comma, period\n",
    "        text = answer.lstrip().replace('TIGER WOODS: ', '').replace(',', '').replace('.', '')\n",
    "        # split text into python list of words\n",
    "        words = text.split()\n",
    "        \n",
    "        ####################################\n",
    "        # DO SHIT HERE TO THE LIST OF WORDS\n",
    "        ####################################\n",
    "        \n",
    "        # fill in dictionary to complete observation\n",
    "        new['date'] = date\n",
    "        new['event'] = event\n",
    "        new['text'] = words\n",
    "        # finally append this dictionary to the grand list\n",
    "        all_data.append(new)\n",
    "\n",
    "print('Done!!')\n",
    "# turn this list of dictionaries into a pandas df\n",
    "#all_data = pd.DataFrame(all_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
